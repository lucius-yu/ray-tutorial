{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-thKr9rm_2rB"
   },
   "source": [
    "# Install Dependencies\n",
    "\n",
    "If you are running on Google Colab, you need to install the necessary dependencies before beginning the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871
    },
    "colab_type": "code",
    "id": "zCb7eB-l_-HH",
    "outputId": "e8d16b55-03ad-41c0-ec70-4a11809599fb"
   },
   "outputs": [],
   "source": [
    "print('NOTE: Intentionally crashing session to use the newly installed library.\\n')\n",
    "\n",
    "!pip uninstall -y pyarrow\n",
    "!pip install ray[debug]==0.7.5\n",
    "!pip install bs4\n",
    "\n",
    "# A hack to force the runtime to restart, needed to include the above dependencies.\n",
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install miss lib for this tutorial\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.5.0-cp37-cp37m-manylinux1_x86_64.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.5.0\n"
     ]
    }
   ],
   "source": [
    "print('Install miss lib for this tutorial')\n",
    "\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6wpgwlHdfus"
   },
   "source": [
    "# Exercise 1 - Simple Parallelization\n",
    "\n",
    "**GOAL:** The goal of this exercise is to show how to run simple tasks in parallel.\n",
    "\n",
    "This script is running too slowly, but the computation is embarrassingly parallel. In this exercise, you will use Ray to execute the functions in parallel to speed it up.\n",
    "\n",
    "### Introduction to Remote Functions\n",
    "\n",
    "The `@ray.remote` decorator turns a Python function into a \"remote function\" that Ray can run in parallel. Here is a simple example:\n",
    "\n",
    "```python\n",
    "# A regular Python function.\n",
    "def regular_function():\n",
    "    return 1\n",
    "\n",
    "# A Ray remote function.\n",
    "@ray.remote\n",
    "def remote_function():\n",
    "    return 1\n",
    "```\n",
    "\n",
    "There are a few key differences between the original function and the decorated one:\n",
    "\n",
    "1. **Invocation:** The regular version is called with `regular_function()`, whereas the remote version is called with `remote_function.remote()`.\n",
    "2. **Return values:** `regular_function` executes synchronously and returns the result of the function (`1`), whereas `remote_function` immediately returns an `ObjectID` (a future) and then executes the task in the background on a separate worker process. The result of the future can be obtained by calling `ray.get` on the `ObjectID`.\n",
    "    ```python\n",
    "    >>> regular_function()\n",
    "    1\n",
    "    \n",
    "    >>> remote_function.remote()\n",
    "    ObjectID(1c80d6937802cd7786ad25e50caf2f023c95e350)\n",
    "    \n",
    "    >>> ray.get(remote_function.remote())\n",
    "    1\n",
    "    ```\n",
    "3. **Parallelism:** Invocations of `regular_function` happen **serially**:\n",
    "    ```python\n",
    "    # These are executed one at a time, back-to-back.\n",
    "    result = 0\n",
    "    for _ in range(4):\n",
    "        result += regular_function()\n",
    "    assert result == 4\n",
    "    ```\n",
    "    In contrast, invocations of `remote_function` happen in **parallel**:\n",
    "    ```python\n",
    "    # Executing these functions happens at the same time in the background, and we get the results using ray.get.\n",
    "    results = []\n",
    "    for _ in range(4):\n",
    "        results.append(remote_function.remote())\n",
    "    assert sum(ray.get(results)) == 4\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLJx-XpJdfuu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported ray!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import ray\n",
    "import time\n",
    "\n",
    "print('Successfully imported ray!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvwwpldHdfux"
   },
   "source": [
    "Start the processes that make up the Ray runtime. By default, Ray does not schedule more tasks concurrently than there are CPUs, but this example requires four tasks to run concurrently, so we tell Ray that there are four CPUs. In practice, you would usually just let Ray detect the number of CPUs on the machine.\n",
    "\n",
    "`ignore_reinit_error=True` just suppresses errors if the cell is run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1MjLO5L4dfux",
    "outputId": "5467e29c-4560-4507-9852-e856238050ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-29 08:53:23,114\tINFO resource_spec.py:212 -- Starting Ray with 55.71 GiB memory available for workers and up to 27.88 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-04-29 08:53:23,548\tINFO services.py:1148 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n",
      "2020-04-29 08:53:23,557\tWARNING services.py:1470 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 2147483648 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_cpus=4, ignore_reinit_error=True)\n",
    "\n",
    "# Sleep a little to improve the accuracy of the timing measurements used below,\n",
    "# because some workers may still be starting up in the background.\n",
    "time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D35JdJQ8dfu1"
   },
   "source": [
    "**EXERCISE:** The loop below takes too long, but the four function calls could be executed in parallel. This should speed up the execution from four seconds to one second. \n",
    "\n",
    "First, turn `slow_function` into a remote function, then execute the tasks in parallel by calling `slow_function.remote()` and obtaining the results with `ray.get` on the list of returned object IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pnNgl3cddfu2",
    "outputId": "27b4becb-0f9c-410d-c613-8595e8b83fea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the for loop took 1.010 seconds.\n",
      "The results are: [0, 1, 2, 3]\n",
      "Run the next cell to check if the exercise was performed correctly.\n"
     ]
    }
   ],
   "source": [
    "# A function simulating a more interesting computation that takes one second.\n",
    "@ray.remote\n",
    "def slow_function(i):\n",
    "    time.sleep(1)\n",
    "    return i\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = []\n",
    "for i in range(4):\n",
    "  results.append(slow_function.remote(i))\n",
    "\n",
    "results = ray.get(results)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print('Executing the for loop took {:.3f} seconds.'.format(duration))\n",
    "print('The results are:', results)\n",
    "print('Run the next cell to check if the exercise was performed correctly.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_FfKxocdfu3"
   },
   "source": [
    "**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "IlrIrAyldfu4",
    "outputId": "0e84fee3-961b-4f87-8075-defc3f85e3de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The example took 1.010368824005127 seconds.\n"
     ]
    }
   ],
   "source": [
    "assert results == [0, 1, 2, 3], 'Did you remember to call ray.get?'\n",
    "assert duration < 1.1, ('The loop took {:.3f} seconds. This is too slow.'\n",
    "                        .format(duration))\n",
    "assert duration > 1, ('The loop took {:.3f} seconds. This is too fast.'\n",
    "                      .format(duration))\n",
    "\n",
    "print('Success! The example took {} seconds.'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AC1rwahidfu5"
   },
   "source": [
    "**EXERCISE:** Use the UI to view the task timeline and to verify that the four tasks were executed in parallel. You can do this as follows.\n",
    "\n",
    "1. Run the following cell to generate a JSON file containing the profiling data.\n",
    "2. Download the timeline file by right clicking on `exercise_1.json` in the **Files** tab in the navigator to the left, right clicking, and selecting  **\"Download\"**.\n",
    "3. Enter **chrome://tracing** into the Chrome web browser, click on the **\"Load\"** button, and select the downloaded JSON file.\n",
    "\n",
    "To navigate within the timeline:\n",
    "- Move around by clicking and dragging.\n",
    "- Zoom in and out by holding **alt** on Windows or **option** on Mac and scrolling.\n",
    "\n",
    "**NOTE:** The timeline visualization will only work in **Chrome**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmYOA4sGdfu6"
   },
   "outputs": [],
   "source": [
    "ray.timeline(filename=\"exercise_1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TD9T8jPYd2bO"
   },
   "source": [
    "# Exercise 2 - Parallel Data Processing with Task Dependencies\n",
    "\n",
    "**GOAL:** The goal of this exercise is to pass object IDs into remote functions to encode dependencies between tasks.\n",
    "\n",
    "In this exercise, we construct a sequence of tasks, each of which depends on the previous, mimicking a data parallel application. Within each sequence, tasks are executed serially, but multiple sequences of tasks can be executed in parallel. You will use Ray to speed up the computation by parallelizing the sequences.\n",
    "\n",
    "### Concept for this Exercise - Task Dependencies\n",
    "\n",
    "Consider the following basic remote function that returns the argument passed to it. If we pass in some normal Python objects, the results returned by `ray.get` should be the same objects.\n",
    "\n",
    "```python\n",
    "@ray.remote\n",
    "def f(x):\n",
    "    return x\n",
    "\n",
    ">>> x1_id = f.remote(1)\n",
    ">>> ray.get(x1_id)\n",
    "1\n",
    "\n",
    ">>> x2_id = f.remote([1, 2, 3])\n",
    ">>> ray.get(x2_id)\n",
    "[1, 2, 3]\n",
    "```\n",
    "\n",
    "However, **object IDs** can also be passed into remote functions. When the function is executed, Ray will automatically substitute the underlying Python object that the object ID refers to. In a sense, it's the same as calling `ray.get` on each argument that's passed in as an argument.\n",
    "\n",
    "```python\n",
    ">>> y1_id = f.remote(x1_id)\n",
    ">>> ray.get(y1_id)\n",
    "1\n",
    "\n",
    ">>> y2_id = f.remote(x2_id)\n",
    ">>> ray.get(y2_id)\n",
    "[1, 2, 3]\n",
    "```\n",
    "\n",
    "When implementing a remote function, the function should expect a regular Python object regardless of whether the caller passes in a regular Python object or an object ID.\n",
    "\n",
    "**These task dependencies affect scheduling.** In the example above, the task that creates `y1_id` depends on the task that creates `x1_id`. This means that:\n",
    "\n",
    "- The second task will not be executed until the first task has finished executing.\n",
    "- If the two tasks are scheduled on different machines, the output of the first task (the value corresponding to `x1_id`) will be copied over the network to the machine where the second task is scheduled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRayjahDd-AU"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "csUGAU13d-Zs",
    "outputId": "945f75d1-0604-4e06-9f65-83c4ad2ec906"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-29 08:12:59,806\tERROR worker.py:682 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_cpus=4, ignore_reinit_error=True)\n",
    "\n",
    "# Sleep a little to improve the accuracy of the timing measurements used below,\n",
    "# because some workers may still be starting up in the background.\n",
    "time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGrF31cceDMk"
   },
   "source": [
    "**EXERCISE:** Below are some helper functions that mimic the pattern of a data parallel application that we want to speed up. To do so, you'll need to turn all of these functions into remote functions. Remember that you don't need to worry about whether the caller passes in an object ID or a regular object, because in both cases the arguments will be regular objects when the function executes. This means that even if you pass in an object ID, you **do not need to call `ray.get`** inside of these remote functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZU1nRG8beACP"
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def load_data(filename):\n",
    "    time.sleep(0.1)\n",
    "    return np.ones((1000, 100))\n",
    "\n",
    "@ray.remote\n",
    "def normalize_data(data):\n",
    "    time.sleep(0.1)\n",
    "    return data - np.mean(data, axis=0)\n",
    "\n",
    "@ray.remote\n",
    "def extract_features(normalized_data):\n",
    "    time.sleep(0.1)\n",
    "    return np.hstack([normalized_data, normalized_data ** 2])\n",
    "\n",
    "@ray.remote\n",
    "def compute_loss(features):\n",
    "    num_data, dim = features.shape\n",
    "    time.sleep(0.1)\n",
    "    return np.sum((np.dot(features, np.ones(dim)) - np.ones(num_data)) ** 2)\n",
    "\n",
    "assert hasattr(load_data, 'remote'), 'load_data must be a remote function'\n",
    "assert hasattr(normalize_data, 'remote'), 'normalize_data must be a remote function'\n",
    "assert hasattr(extract_features, 'remote'), 'extract_features must be a remote function'\n",
    "assert hasattr(compute_loss, 'remote'), 'compute_loss must be a remote function'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TlF-_kc2eHc4"
   },
   "source": [
    "**EXERCISE:** The loop below takes too long. Parallelize the four passes through the loop by turning `load_data`, `normalize_data`, `extract_features`, and `compute_loss` into remote functions and then retrieving the losses with `ray.get`.\n",
    "\n",
    "**NOTE:** You should only use **ONE** call to `ray.get`. For example, the object ID returned by `load_data` should be passed directly into `normalize_data` without needing to be retrieved by the driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "rX-brDlaeFNZ",
    "outputId": "19edc9bb-b9ae-45f8-d4a4-46c9313be859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The losses are [1000.0, 1000.0, 1000.0, 1000.0].\n",
      "\n",
      "The loss is 4000.0. This took 0.443 seconds. Run the next cell to see if the exercise was done correctly.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "losses = []\n",
    "for filename in ['file1', 'file2', 'file3', 'file4']:\n",
    "    inner_start = time.time()\n",
    "\n",
    "    data = load_data.remote(filename)\n",
    "    normalized_data = normalize_data.remote(data)\n",
    "    features = extract_features.remote(normalized_data)\n",
    "    loss = compute_loss.remote(features)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    inner_end = time.time()\n",
    "    \n",
    "    if inner_end - inner_start >= 0.1:\n",
    "        raise Exception('You may be calling ray.get inside of the for loop! '\n",
    "                        'Doing this will prevent parallelism from being exposed. '\n",
    "                        'Make sure to only call ray.get once outside of the for loop.')\n",
    "\n",
    "losses = ray.get(losses)\n",
    "print('The losses are {}.'.format(losses) + '\\n')\n",
    "loss = sum(losses)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "\n",
    "print('The loss is {}. This took {:.3f} seconds. Run the next cell to see '\n",
    "      'if the exercise was done correctly.'.format(loss, duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOevdR4LeLlk"
   },
   "source": [
    "**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlTAyw09eJSL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The example took 0.443 seconds.\n"
     ]
    }
   ],
   "source": [
    "assert loss == 4000\n",
    "assert duration < 0.8, ('The loop took {:.3f} seconds. This is too slow.'\n",
    "                        .format(duration))\n",
    "assert duration > 0.4, ('The loop took {:.3f} seconds. This is too fast.'\n",
    "                        .format(duration))\n",
    "\n",
    "print('Success! The example took {:.3f} seconds.'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1fHJZWDeRGb"
   },
   "source": [
    "**EXERCISE:** Use the UI to view the task timeline and to verify that the four tasks were executed in parallel. You can do this as follows.\n",
    "\n",
    "1. Run the following cell to generate a JSON file containing the profiling data.\n",
    "2. Download the timeline file by right clicking on `exercise_2.json` in the **Files** tab in the navigator to the left, right clicking, and selecting  **\"Download\"**.\n",
    "3. Enter **chrome://tracing** into the Chrome web browser, click on the **\"Load\"** button, and select the downloaded JSON file.\n",
    "\n",
    "To navigate within the timeline:\n",
    "- Move around by clicking and dragging.\n",
    "- Zoom in and out by holding **alt** on Windows or **option** on Mac and scrolling.\n",
    "\n",
    "**NOTE:** The timeline visualization will only work in **Chrome**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R96y_U99eRdg"
   },
   "outputs": [],
   "source": [
    "ray.timeline(filename=\"exercise_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UMNWDWOeVI2"
   },
   "source": [
    "### Application: Parallel web-scraping\n",
    "\n",
    "One useful application of what we have learned so far is to scrape information from the web. We will illustrate this in a toy setting, but the same principles apply on a large scale where crawling through websites, parsing them and extracting useful content (e.g. for building a search index or populating a database) is often very computationally demanding.\n",
    "\n",
    "We break up the process into multiple steps. We first grab the raw HTML of the website using Python's requests package. Then, we use BeautifulSoup to parse the HTML to find the relevant information. Finally, we populate a pandas DataFrames so that we are able to work with the data.\n",
    "\n",
    "To demonstrate this, we scrape GitHub commits to see the latest commits on several repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6apTGnCZeTDA"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IYW3fS-Aeg2s"
   },
   "source": [
    "The following function uses these libraries to parse the latest commits from several repositories on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXRdG9zYehhI"
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def fetch_commits(repo):\n",
    "    url = 'https://github.com/{}/commits/master'.format(repo)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    df = pd.DataFrame(columns=['title', 'link'])\n",
    "    for g in soup.find_all(class_='commit-title'):\n",
    "        entry = {}\n",
    "        title = g.find_all(class_='message')[0]['aria-label']\n",
    "        entry['title'] = title\n",
    "        links = g.find_all(class_='issue-link')\n",
    "        if len(links) >= 1:\n",
    "            link = links[0]['data-url']\n",
    "            entry['link'] = link\n",
    "        df = df.append(pd.DataFrame(entry, index=[0]), sort=False)\n",
    "    \n",
    "    df['repository'] = repo\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjhbi8UXen7d"
   },
   "source": [
    "Let's try this out to get results for some ray related topics serially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XENYO57kepSU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing the dataframe took 2.721 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "repos = [\"ray-project/ray\", \"modin-project/modin\", \"tensorflow/tensorflow\", \"apache/arrow\"]\n",
    "results = []\n",
    "for repo in repos:\n",
    "    df = fetch_commits.remote(repo)\n",
    "    results.append(df)\n",
    "    \n",
    "df = pd.concat(ray.get(results), sort=False)\n",
    "duration = time.time() - start\n",
    "print(\"Constructing the dataframe took {:.3f} seconds.\".format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZ5VmqgoerPb"
   },
   "source": [
    "**EXERCISE**: Speed up the above serial query by making `fetch_commits` a remote function in order to scrape GitHub results in parallel. Then, see a sample of the data scraped below and feel free to play with the data to find other resources to learn more about these libraries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58RIGdF1etXY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>repository</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fix release 0.8.5 tests for PPO torch Breakout...</td>\n",
       "      <td>https://github.com/ray-project/ray/issues/8226</td>\n",
       "      <td>ray-project/ray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Streaming] Streaming Cross-Lang API (#7464)</td>\n",
       "      <td>https://github.com/ray-project/ray/issues/7464</td>\n",
       "      <td>ray-project/ray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Serve] RayServe TF, PyTorch, Sklearn Examples...</td>\n",
       "      <td>https://github.com/ray-project/ray/issues/8156</td>\n",
       "      <td>ray-project/ray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[RayServe] Specify installation instruction in...</td>\n",
       "      <td>https://github.com/ray-project/ray/issues/8220</td>\n",
       "      <td>ray-project/ray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tune] Hotfix for test_ls (#8215)</td>\n",
       "      <td>https://github.com/ray-project/ray/issues/8215</td>\n",
       "      <td>ray-project/ray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARROW-8569: [CI] Upgrade xcode version for tes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apache/arrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARROW-8065: [C++][Dataset] Refactor ScanOption...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apache/arrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARROW-8571: [C++] Switch AppVeyor image to VS ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apache/arrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARROW-3329: [Python] Python tests for decimal ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apache/arrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARROW-8560: [Rust] Docs for MutableBuffer resi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apache/arrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Fix release 0.8.5 tests for PPO torch Breakout...   \n",
       "0        [Streaming] Streaming Cross-Lang API (#7464)   \n",
       "0   [Serve] RayServe TF, PyTorch, Sklearn Examples...   \n",
       "0   [RayServe] Specify installation instruction in...   \n",
       "0                   [tune] Hotfix for test_ls (#8215)   \n",
       "..                                                ...   \n",
       "0   ARROW-8569: [CI] Upgrade xcode version for tes...   \n",
       "0   ARROW-8065: [C++][Dataset] Refactor ScanOption...   \n",
       "0   ARROW-8571: [C++] Switch AppVeyor image to VS ...   \n",
       "0   ARROW-3329: [Python] Python tests for decimal ...   \n",
       "0   ARROW-8560: [Rust] Docs for MutableBuffer resi...   \n",
       "\n",
       "                                              link       repository  \n",
       "0   https://github.com/ray-project/ray/issues/8226  ray-project/ray  \n",
       "0   https://github.com/ray-project/ray/issues/7464  ray-project/ray  \n",
       "0   https://github.com/ray-project/ray/issues/8156  ray-project/ray  \n",
       "0   https://github.com/ray-project/ray/issues/8220  ray-project/ray  \n",
       "0   https://github.com/ray-project/ray/issues/8215  ray-project/ray  \n",
       "..                                             ...              ...  \n",
       "0                                              NaN     apache/arrow  \n",
       "0                                              NaN     apache/arrow  \n",
       "0                                              NaN     apache/arrow  \n",
       "0                                              NaN     apache/arrow  \n",
       "0                                              NaN     apache/arrow  \n",
       "\n",
       "[140 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-c-u7Nvewci"
   },
   "source": [
    "# Exercise 3 - Nested Parallelism\n",
    "\n",
    "**GOAL:** The goal of this exercise is to show how to create nested tasks by calling a remote function inside of another remote function.\n",
    "\n",
    "In this exercise, you will implement the structure of a parallel hyperparameter sweep which trains a number of models in parallel. Each model will be trained using parallel gradient computations.\n",
    "\n",
    "### Concepts for this Exercise - Nested Remote Functions\n",
    "\n",
    "Remote functions can call other functions. For example, consider the following.\n",
    "\n",
    "```python\n",
    "@ray.remote\n",
    "def f():\n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def g():\n",
    "    # Call f 4 times and return the resulting object IDs.\n",
    "    results = []\n",
    "    for _ in range(4):\n",
    "      results.append(f.remote())\n",
    "    return results\n",
    "\n",
    "@ray.remote\n",
    "def h():\n",
    "    # Call f 4 times, block until those 4 tasks finish,\n",
    "    # retrieve the results, and return the values.\n",
    "    results = []\n",
    "    for _ in range(4):\n",
    "      results.append(f.remote())\n",
    "    return ray.get(results)\n",
    "```\n",
    "\n",
    "Then calling `g` and `h` produces the following behavior.\n",
    "\n",
    "```python\n",
    ">>> ray.get(g.remote())\n",
    "[ObjectID(b1457ba0911ae84989aae86f89409e953dd9a80e),\n",
    " ObjectID(7c14a1d13a56d8dc01e800761a66f09201104275),\n",
    " ObjectID(99763728ffc1a2c0766a2000ebabded52514e9a6),\n",
    " ObjectID(9c2f372e1933b04b2936bb6f58161285829b9914)]\n",
    "\n",
    ">>> ray.get(h.remote())\n",
    "[1, 1, 1, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppUDwvBMe0ue"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2aEuUdJDe-uY",
    "outputId": "abb2702a-d8ff-4e97-c0c2-223ac6be1b76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-29 08:54:19,782\tERROR worker.py:682 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_cpus=9, ignore_reinit_error=True)\n",
    "\n",
    "# Sleep a little to improve the accuracy of the timing measurements used below,\n",
    "# because some workers may still be starting up in the background.\n",
    "time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RKX1DnmbfAJv"
   },
   "source": [
    "This example represents a hyperparameter sweep in which multiple models are trained in parallel. Each model training task also performs data parallel gradient computations.\n",
    "\n",
    "**EXERCISE:** Turn `compute_gradient` and `train_model` into remote functions so that they can be executed in parallel. Inside of `train_model`, do the calls to `compute_gradient` in parallel and fetch the results using `ray.get`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GAdMoSp7fBxV"
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def compute_gradient(data, current_model):\n",
    "    time.sleep(0.03)\n",
    "    return 1\n",
    "\n",
    "    \n",
    "@ray.remote\n",
    "def train_model(hyperparameters):\n",
    "    current_model = 0\n",
    "    # Iteratively improve the current model. This outer loop cannot be parallelized.\n",
    "    for _ in range(10):\n",
    "        # EXERCISE: Parallelize computing the gradients below. Note that we still need\n",
    "        # to get all of the results in order to compute the updated model (by taking\n",
    "        # the sum), so it's ok to call ray.get() inside of the loop here.\n",
    "        gradients = []\n",
    "        for j in range(2):\n",
    "            gradients.append(compute_gradient.remote(j, current_model))\n",
    "        current_model += sum(ray.get(gradients))\n",
    "\n",
    "    return current_model\n",
    "\n",
    "assert hasattr(compute_gradient, 'remote'), 'compute_gradient must be a remote function'\n",
    "assert hasattr(train_model, 'remote'), 'train_model must be a remote function'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6yR2xgWhfEK3"
   },
   "source": [
    "**EXERCISE:** The code below runs 3 hyperparameter experiments. Change this to run the experiments in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQhgStdSfGMt"
   },
   "outputs": [],
   "source": [
    "# Sleep a little to improve the accuracy of the timing measurements below.\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "# Run some hyperparaameter experiments.\n",
    "results = []\n",
    "for hyperparameters in [{'learning_rate': 1e-1, 'batch_size': 100},\n",
    "                        {'learning_rate': 1e-2, 'batch_size': 100},\n",
    "                        {'learning_rate': 1e-3, 'batch_size': 100}]:\n",
    "    results.append(train_model.remote(hyperparameters))\n",
    "\n",
    "# EXERCISE: Once you've turned \"results\" into a list of Ray ObjectIDs\n",
    "# by calling train_model.remote, you will need to turn \"results\" back\n",
    "# into a list of integers, e.g., by doing \"results = ray.get(results)\".\n",
    "results = ray.get(results)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "assert all([isinstance(x, int) for x in results]), \\\n",
    "    'Looks like \"results\" is {}. You may have forgotten to call ray.get.'.format(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZbRvJ9JfJcl"
   },
   "source": [
    "**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass.\n",
    "\n",
    "**NOTE:** This exercise is known to have issues running on remote notebooks that can be resolved by rerunning the above cell a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BN6QZZGEfLAu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The example took 0.491 seconds.\n"
     ]
    }
   ],
   "source": [
    "assert results == [20, 20, 20]\n",
    "assert duration < 0.5, ('The experiments ran in {:.3f} seconds. This is too '\n",
    "                         'slow.'.format(duration))\n",
    "assert duration > 0.3, ('The experiments ran in {:.3f} seconds. This is too '\n",
    "                        'fast.'.format(duration))\n",
    "\n",
    "print('Success! The example took {:.3f} seconds.'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xuf2d5mrfMms"
   },
   "source": [
    "**EXERCISE:** Use the UI to view the task timeline and to verify that the four tasks were executed in parallel. You can do this as follows.\n",
    "\n",
    "1. Run the following cell to generate a JSON file containing the profiling data.\n",
    "2. Download the timeline file by right clicking on `exercise_3.json` in the **Files** tab in the navigator to the left, right clicking, and selecting  **\"Download\"**.\n",
    "3. Enter **chrome://tracing** into the Chrome web browser, click on the **\"Load\"** button, and select the downloaded JSON file.\n",
    "\n",
    "To navigate within the timeline:\n",
    "- Move around by clicking and dragging.\n",
    "- Zoom in and out by holding **alt** on Windows or **option** on Mac and scrolling.\n",
    "\n",
    "**NOTE:** The timeline visualization will only work in **Chrome**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WoR39fnfOlx"
   },
   "outputs": [],
   "source": [
    "ray.timeline(filename=\"exercise_3.json\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ray Tutorial - Remote Functions",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
